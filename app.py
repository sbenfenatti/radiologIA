# app.py - VERS√ÉO COM SELE√á√ÉO DE MODELO E U-NET OTIMIZADO
import os
import io
import asyncio
import functools 
import traceback 
from contextlib import asynccontextmanager
import numpy as np
from PIL import Image
import cv2
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import torchvision
from ultralytics import YOLO
import httpx
from scipy import ndimage
from skimage.measure import label, regionprops
from skimage.morphology import remove_small_objects, closing, disk

from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional

# -----------------------------------------------------------------------------
# 1. ARQUITETURA U-NET CORRIGIDA PARA CORRESPONDER AO MODELO TREINADO
# -----------------------------------------------------------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

class Down(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)

class Up(nn.Module):
    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=5, bilinear=False):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor)
        self.up1 = Up(1024, 512 // factor, bilinear)
        self.up2 = Up(512, 256 // factor, bilinear)
        self.up3 = Up(256, 128 // factor, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits

# -----------------------------------------------------------------------------
# 2. DEFINI√á√ÉO DOS MODELOS DE DADOS (PYDANTIC)
# -----------------------------------------------------------------------------
class Finding(BaseModel):
    id: str
    label: str
    confidence: float
    segmentation: List[List[float]]
    model_type: str = "YOLO"
    area: Optional[float] = None

class AnalysisResponse(BaseModel):
    findings: List[Finding]
    model_used: str
    status: str

class ChatPart(BaseModel):
    text: str

class ChatContent(BaseModel):
    role: str
    parts: List[ChatPart]

class ChatHistory(BaseModel):
    history: List[ChatContent]

# -----------------------------------------------------------------------------
# 3. CONFIGURA√á√ÉO INICIAL E CICLO DE VIDA DA APLICA√á√ÉO
# -----------------------------------------------------------------------------
lifespan_storage = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("üöÄ Iniciando a aplica√ß√£o...")
    lifespan_storage['gemini_api_key'] = os.getenv('GEMINI_API_KEY')
    if not lifespan_storage['gemini_api_key']:
        print("‚ùå AVISO: A vari√°vel de ambiente 'GEMINI_API_KEY' n√£o foi encontrada.")
    
    try:
        # Carregar modelo YOLO
        print("üì• Carregando modelo YOLO...")
        yolo_path = 'models/best.pt'
        if os.path.exists(yolo_path):
            lifespan_storage['yolo_model'] = YOLO(yolo_path)
            print("‚úÖ Modelo YOLO carregado com sucesso.")
        else:
            print(f"‚ö†Ô∏è Modelo YOLO n√£o encontrado em: {yolo_path}")
            lifespan_storage['yolo_model'] = None
        
        # Carregar modelo U-Net 
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üì± Usando dispositivo: {device}")
        lifespan_storage['device'] = device
        
        print("üì• Tentando carregar modelo U-Net...")
        unet_path = 'models/radiologia_5classes_fold_1_best.pth'
        
        if os.path.exists(unet_path):
            print(f"üìÇ Arquivo U-Net encontrado: {unet_path}")
            try:
                unet_model = UNet(n_channels=3, n_classes=5, bilinear=False)
                checkpoint = torch.load(unet_path, map_location=device)
                
                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint
                
                unet_model.load_state_dict(state_dict, strict=False)
                unet_model.to(device)
                unet_model.eval()
                
                lifespan_storage['unet_model'] = unet_model
                print("‚úÖ Modelo U-Net carregado com sucesso.")
                
            except Exception as unet_error:
                print(f"‚ö†Ô∏è Erro ao carregar U-Net: {unet_error}")
                print("üìù Modelo U-Net incompat√≠vel com arquitetura atual")
                lifespan_storage['unet_model'] = None
        else:
            print(f"‚ö†Ô∏è Modelo U-Net n√£o encontrado em: {unet_path}")
            lifespan_storage['unet_model'] = None
            
    except Exception as e:
        print(f"‚ùå Erro geral ao carregar modelos: {e}")
        print(f"üìù Detalhes do erro: {traceback.format_exc()}")
        lifespan_storage['yolo_model'] = None
        lifespan_storage['unet_model'] = None
    
    lifespan_storage['http_client'] = httpx.AsyncClient()
    print("‚úÖ Cliente HTTP ass√≠ncrono criado.")
    print("üéâ Aplica√ß√£o iniciada com sucesso!")
    yield
    print("üëã Encerrando a aplica√ß√£o...")
    await lifespan_storage['http_client'].aclose()

app = FastAPI(lifespan=lifespan)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- MAPEAMENTO DE LABELS ---
LABEL_MAP = {
    "lesao_periapical": "Les√£o Periapical",
    "carie": "C√°rie",
    "fratura_radicular": "Fratura Radicular",
    "calculo_dental": "C√°lculo Dental",
    "restauracao": "Restaura√ß√£o",
    "implante": "Implante",
    "dente_incluso": "Dente Incluso",
    "pre_molar_inf": "Pr√©-Molar Inferior",
    "jaw": "Mand√≠bula",
    "incisivo_lateral_inf": "Incisivo Lateral Inferior",
    "incisivo_central_sup": "Incisivo Central Superior",
    "molar_inf": "Molar Inferior",
    "maxila": "Maxila",
    "incisivo_lateral_sup": "Incisivo Lateral Superior",
    "incisivo_central_inf": "Incisivo Central Inferior",
    "molar_sup": "Molar Superior",
    "pre_molar_sup": "Pr√©-Molar Superior",
    "canino_inf": "Canino Inferior",
    "canino_sup": "Canino Superior",
}

# Mapeamento para classes U-Net otimizado
UNET_CLASS_MAP = {
    0: "background",
    1: "mandibula",
    2: "maxila", 
    3: "dente",
    4: "canal"
}

# -----------------------------------------------------------------------------
# 4. FUN√á√ïES DE P√ìS-PROCESSAMENTO U-NET OTIMIZADAS
# -----------------------------------------------------------------------------
def merge_nearby_contours(contours, distance_threshold=50):
    """Merge contornos pr√≥ximos para reduzir fragmenta√ß√£o"""
    if len(contours) <= 1:
        return contours
    
    merged = []
    used = set()
    
    for i, contour1 in enumerate(contours):
        if i in used:
            continue
            
        # Come√ßar um novo grupo de contornos
        group = [contour1]
        used.add(i)
        
        # Encontrar contornos pr√≥ximos
        for j, contour2 in enumerate(contours):
            if j in used or i == j:
                continue
                
            # Calcular dist√¢ncia entre centroides
            M1 = cv2.moments(contour1)
            M2 = cv2.moments(contour2)
            
            if M1["m00"] > 0 and M2["m00"] > 0:
                cx1, cy1 = int(M1["m10"] / M1["m00"]), int(M1["m01"] / M1["m00"])
                cx2, cy2 = int(M2["m10"] / M2["m00"]), int(M2["m01"] / M2["m00"])
                distance = np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)
                
                if distance < distance_threshold:
                    group.append(contour2)
                    used.add(j)
        
        # Se h√° m√∫ltiplos contornos no grupo, merge them
        if len(group) > 1:
            # Combinar todos os contornos do grupo
            combined_contour = np.vstack(group)
            hull = cv2.convexHull(combined_contour)
            merged.append(hull)
        else:
            merged.append(group[0])
    
    return merged

def clean_segmentation_mask(mask, min_area=500, closing_size=3):
    """Limpa m√°scara de segmenta√ß√£o removendo ru√≠do e pequenos objetos"""
    # Aplicar morfologia matem√°tica para fechar buracos
    if closing_size > 0:
        kernel = disk(closing_size)
        mask = closing(mask, kernel)
    
    # Remover objetos pequenos
    mask_cleaned = remove_small_objects(mask.astype(bool), min_size=min_area)
    
    return mask_cleaned.astype(np.uint8)

def extract_major_regions(mask, max_regions=5, min_area_ratio=0.05):
    """Extrai apenas as regi√µes principais da m√°scara"""
    # Rotular regi√µes conectadas
    labeled_mask = label(mask)
    regions = regionprops(labeled_mask)
    
    if not regions:
        return mask
    
    # Calcular √°rea total
    total_area = mask.sum()
    min_area = total_area * min_area_ratio
    
    # Filtrar regi√µes por tamanho
    major_regions = [r for r in regions if r.area >= min_area]
    
    # Ordenar por √°rea (maiores primeiro)
    major_regions.sort(key=lambda x: x.area, reverse=True)
    
    # Manter apenas as maiores regi√µes
    major_regions = major_regions[:max_regions]
    
    # Criar nova m√°scara apenas com regi√µes principais
    new_mask = np.zeros_like(mask)
    for region in major_regions:
        coords = region.coords
        new_mask[coords[:, 0], coords[:, 1]] = 1
    
    return new_mask

def preprocess_for_unet(image_pil, target_size=(512, 512)):
    """Preprocessa imagem para entrada no U-Net"""
    print(f"üîÑ Preprocessando imagem para U-Net: {target_size}")
    
    image_resized = image_pil.resize(target_size, Image.LANCZOS)
    
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    tensor = transform(image_resized).unsqueeze(0)
    return tensor, target_size

def analyze_with_unet(image_pil, unet_model, device):
    """Analisa imagem usando modelo U-Net com p√≥s-processamento otimizado"""
    print("üî¨ Iniciando an√°lise com U-Net otimizada...")
    
    if unet_model is None:
        return []
    
    try:
        input_tensor, unet_size = preprocess_for_unet(image_pil)
        input_tensor = input_tensor.to(device)
        print(f"üìä Tensor de entrada: {input_tensor.shape}")
        
        with torch.no_grad():
            print("üß† Executando predi√ß√£o U-Net...")
            unet_output = unet_model(input_tensor)
            print(f"üìä Sa√≠da U-Net: {unet_output.shape}")
            
            unet_probs = torch.softmax(unet_output, dim=1)
            unet_masks = torch.argmax(unet_probs, dim=1).squeeze(0).cpu().numpy()
            probs_numpy = unet_probs.squeeze(0).cpu().numpy()
            
            unique_classes = np.unique(unet_masks)
            print(f"üìä M√°scaras U-Net: {unet_masks.shape}, classes √∫nicas: {unique_classes}")
        
        findings = []
        original_size = image_pil.size
        print(f"üîÑ Processando segmenta√ß√µes otimizadas para tamanho original: {original_size}")
        
        # Par√¢metros de filtros espec√≠ficos por classe
        class_params = {
            1: {"min_area": 5000, "max_regions": 2, "merge_distance": 100, "label": "Mand√≠bula"},    # Mand√≠bula - grandes regi√µes
            2: {"min_area": 3000, "max_regions": 2, "merge_distance": 80, "label": "Maxila"},      # Maxila - grandes regi√µes  
            3: {"min_area": 800, "max_regions": 20, "merge_distance": 30, "label": "Dente"},       # Dentes - m√∫ltiplas regi√µes menores
            4: {"min_area": 200, "max_regions": 10, "merge_distance": 20, "label": "Canal"}        # Canais - regi√µes pequenas
        }
        
        for class_id in range(1, len(UNET_CLASS_MAP)):
            class_name = UNET_CLASS_MAP.get(class_id, f"class_{class_id}")
            
            if class_id not in unique_classes:
                print(f"‚ö™ Classe {class_name} (ID {class_id}): n√£o detectada")
                continue
                
            params = class_params.get(class_id, {"min_area": 500, "max_regions": 5, "merge_distance": 50, "label": class_name.title()})
            
            # Criar m√°scara bin√°ria para a classe
            class_mask = (unet_masks == class_id).astype(np.uint8)
            pixel_count = class_mask.sum()
            print(f"üîç Classe {class_name} (ID {class_id}): {pixel_count} pixels")
            
            if pixel_count < params["min_area"] // 4:  # Threshold muito baixo
                print(f"‚ö™ {class_name}: muito poucos pixels, ignorando")
                continue
                
            # Limpeza da m√°scara
            class_mask_clean = clean_segmentation_mask(
                class_mask, 
                min_area=params["min_area"] // 10,  # Mais permissivo na limpeza inicial
                closing_size=2
            )
            
            # Extrair apenas regi√µes principais
            class_mask_major = extract_major_regions(
                class_mask_clean,
                max_regions=params["max_regions"],
                min_area_ratio=0.01  # 1% da √°rea total da classe
            )
            
            cleaned_pixel_count = class_mask_major.sum()
            print(f"üßπ {class_name}: {pixel_count} ‚Üí {cleaned_pixel_count} pixels ap√≥s limpeza")
            
            if cleaned_pixel_count < params["min_area"] // 4:
                print(f"‚ö™ {class_name}: √°rea insuficiente ap√≥s limpeza")
                continue
            
            # Redimensionar para tamanho original
            class_mask_resized = cv2.resize(
                class_mask_major, 
                original_size, 
                interpolation=cv2.INTER_NEAREST
            )
            
            # Encontrar contornos
            contours, _ = cv2.findContours(
                class_mask_resized, 
                cv2.RETR_EXTERNAL, 
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            if not contours:
                continue
                
            # Merge contornos pr√≥ximos
            contours = merge_nearby_contours(contours, params["merge_distance"])
            print(f"üîó {class_name}: {len(contours)} contornos ap√≥s merge")
            
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                if area < params["min_area"]:
                    continue
                    
                # Calcular confian√ßa baseada na probabilidade m√©dia da regi√£o
                mask_region = np.zeros_like(class_mask_resized)
                cv2.fillPoly(mask_region, [contour], 1)
                mask_region_unet = cv2.resize(mask_region, unet_size, interpolation=cv2.INTER_NEAREST)
                
                confidence = float(probs_numpy[class_id][mask_region_unet > 0].mean()) if mask_region_unet.sum() > 0 else 0.5
                
                # Simplificar contorno
                epsilon = 0.005 * cv2.arcLength(contour, True)
                contour_simplified = cv2.approxPolyDP(contour, epsilon, True)
                
                if len(contour_simplified) < 3:
                    continue
                    
                # Normalizar coordenadas (0-100)
                contour_normalized = contour_simplified.reshape(-1, 2).astype(float)
                contour_normalized[:, 0] = (contour_normalized[:, 0] / original_size[0]) * 100
                contour_normalized[:, 1] = (contour_normalized[:, 1] / original_size[1]) * 100
                
                findings.append({
                    "id": f"unet_{class_name}_{i}",
                    "label": params["label"],
                    "confidence": max(0.5, min(0.95, confidence)),
                    "segmentation": contour_normalized.tolist(),
                    "model_type": "U-Net",
                    "area": area
                })
                
                print(f"‚úÖ {params['label']}: confian√ßa={confidence:.3f}, √°rea={area:.0f}")
        
        print(f"üéâ An√°lise U-Net otimizada conclu√≠da: {len(findings)} achados")
        return findings
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise U-Net: {e}")
        print(f"üìù Traceback: {traceback.format_exc()}")
        return []

async def run_yolo_prediction(model, image):
    """Executa predi√ß√£o YOLO de forma ass√≠ncrona"""
    print("üîÑ Executando predi√ß√£o YOLO...")
    loop = asyncio.get_event_loop()
    predict_with_args = functools.partial(model.predict, source=image, conf=0.5)
    results = await loop.run_in_executor(None, predict_with_args)
    return results

def analyze_with_yolo(image, yolo_model):
    """Analisa imagem usando modelo YOLO"""
    print("üéØ Iniciando an√°lise com YOLO...")
    
    if yolo_model is None:
        return []
    
    try:
        results = yolo_model.predict(source=image, conf=0.5)
        findings = []
        
        if not results:
            return findings

        prediction = results[0]
        class_names = prediction.names if hasattr(prediction, 'names') else {}
        
        print(f"üìä Classes YOLO dispon√≠veis: {class_names}")

        if hasattr(prediction, 'masks') and prediction.masks is not None:
            print(f"üîç Processando {len(prediction.masks)} m√°scaras YOLO...")
            
            for i, box in enumerate(prediction.boxes):
                try:
                    if i < len(prediction.masks.xyn):
                        cls_id = int(box.cls[0].item()) if hasattr(box.cls[0], 'item') else int(box.cls[0])
                        technical_label = class_names.get(cls_id, "Desconhecido")
                        friendly_label = LABEL_MAP.get(technical_label, technical_label.replace("_", " ").title())
                        
                        mask_points = prediction.masks.xyn[i]
                        confidence = float(box.conf[0].item()) if hasattr(box.conf[0], 'item') else float(box.conf[0])
                        
                        findings.append({
                            "id": f"yolo_finding_{i}",
                            "label": friendly_label,
                            "confidence": confidence,
                            "segmentation": (mask_points * 100).tolist(),
                            "model_type": "YOLO"
                        })
                        
                        print(f"‚úÖ YOLO - {friendly_label}: {confidence:.3f}")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro processando detec√ß√£o YOLO {i}: {e}")
                    continue
        else:
            print("‚ö†Ô∏è Nenhuma m√°scara encontrada no resultado YOLO")
        
        return findings
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise YOLO: {e}")
        print(f"üìù Traceback: {traceback.format_exc()}")
        return []

# -----------------------------------------------------------------------------
# 5. ENDPOINT PRINCIPAL COM SELE√á√ÉO DE MODELO
# -----------------------------------------------------------------------------
@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_image(file: UploadFile = File(...), model_type: str = Form(default="yolo")):
    print("\n" + "="*50)
    print(f"üì° Rota /analyze acessada com modelo: {model_type.upper()}")
    print("="*50)
    
    yolo_model = lifespan_storage.get('yolo_model')
    unet_model = lifespan_storage.get('unet_model')
    device = lifespan_storage.get('device', 'cpu')
    
    model_type = model_type.lower()
    if model_type not in ["yolo", "unet"]:
        raise HTTPException(status_code=400, detail="Tipo de modelo deve ser 'yolo' ou 'unet'")
    
    if model_type == "yolo" and not yolo_model:
        raise HTTPException(status_code=500, detail="Modelo YOLO n√£o est√° dispon√≠vel")
    
    if model_type == "unet" and not unet_model:
        raise HTTPException(status_code=500, detail="Modelo U-Net n√£o est√° dispon√≠vel")
    
    try:
        print("üì• Lendo arquivo de imagem...")
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        print(f"üìä Imagem carregada: {image.size}")
        
        if model_type == "yolo":
            print("üéØ Executando an√°lise com YOLO")
            findings = analyze_with_yolo(image, yolo_model)
            model_used = "YOLO"
            
        elif model_type == "unet":
            print("üî¨ Executando an√°lise com U-Net")
            findings = analyze_with_unet(image, unet_model, device)
            model_used = "U-Net"
        
        print(f"\nüéâ An√°lise conclu√≠da com {model_used}")
        print(f"üìä Total de achados: {len(findings)}")
        print("="*50)
        
        return {
            "findings": findings,
            "model_used": model_used,
            "status": "success"
        }
        
    except Exception as e:
        print(f"‚ùå Erro cr√≠tico na an√°lise: {e}")
        print(f"üìù Traceback completo:")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erro interno do servidor: {str(e)}")

# -----------------------------------------------------------------------------
# 6. ENDPOINT PARA VERIFICAR MODELOS DISPON√çVEIS
# -----------------------------------------------------------------------------
@app.get("/models/available")
async def get_available_models():
    """Retorna quais modelos est√£o dispon√≠veis"""
    yolo_available = lifespan_storage.get('yolo_model') is not None
    unet_available = lifespan_storage.get('unet_model') is not None
    
    return {
        "yolo": yolo_available,
        "unet": unet_available,
        "default": "yolo" if yolo_available else ("unet" if unet_available else None)
    }

# -----------------------------------------------------------------------------
# 7. ENDPOINT CHAT (INALTERADO)
# -----------------------------------------------------------------------------
@app.post("/chat")
async def handle_chat(payload: ChatHistory):
    print("\nüì° Rota /chat acessada!")
    api_key = lifespan_storage.get('gemini_api_key')
    client = lifespan_storage.get('http_client')
    
    if not api_key:
        raise HTTPException(status_code=500, detail="A chave da API do Gemini n√£o est√° configurada no servidor.")
    
    gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    request_body = {"contents": [item.dict() for item in payload.history]}
    
    try:
        response = await client.post(gemini_api_url, headers=headers, json=request_body, timeout=60.0)
        response.raise_for_status()
        print("‚úÖ Resposta da API Gemini recebida com sucesso.")
        return response.json()
        
    except httpx.RequestError as e:
        print(f"‚ùå Erro ao chamar a API do Gemini: {e}")
        raise HTTPException(status_code=503, detail=f"Erro de comunica√ß√£o com a API do Gemini: {e}")
        
    except Exception as e:
        print(f"‚ùå Erro Cr√≠tico no chat: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="Erro interno do servidor no processamento do chat")

# -----------------------------------------------------------------------------
# 8. SERVINDO ARQUIVOS EST√ÅTICOS
# -----------------------------------------------------------------------------
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
async def serve_index():
    return FileResponse('static/index.html')

@app.get("/{path:path}")
async def serve_static_files(path: str):
    file_path = os.path.join('static', path)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    return FileResponse('static/index.html')