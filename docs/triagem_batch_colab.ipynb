{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triagem batch - Colab\n",
    "\n",
    "Notebook para gerar JSON de achados usando o mesmo lote de radiografias do projeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Upload do zip (imagens + modelos)\n",
    "Envie um zip com as imagens e os modelos. Localmente: `zip -r batch_test.zip doc/batch_test`.\n",
    "Pode ser um unico zip contendo, por exemplo:\n",
    "- images/ (radiografias)\n",
    "- models/ (pesos dos modelos)\n",
    "\n",
    "Se preferir, pode enviar mais de um zip (ex: um com imagens e outro com modelos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "uploaded = files.upload()\n",
    "if not uploaded:\n",
    "    raise SystemExit(\"Nenhum arquivo enviado.\")\n",
    "\n",
    "extract_dir = \"/content/triagem_payload\"\n",
    "if os.path.exists(extract_dir):\n",
    "    shutil.rmtree(extract_dir)\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "for filename, data in uploaded.items():\n",
    "    if not filename.lower().endswith(\".zip\"):\n",
    "        print(f\"Ignorando {filename} (nao e zip)\")\n",
    "        continue\n",
    "    with zipfile.ZipFile(io.BytesIO(data)) as z:\n",
    "        z.extractall(extract_dir)\n",
    "        print(f\"Extraido: {filename}\")\n",
    "\n",
    "print(\"Diretorio base:\", extract_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Preparar ambiente\n",
    "Ajuste as instalacoes conforme o framework do seu modelo.\n",
    "Defina o tipo de modelo e os caminhos para os pesos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacao de dependencias (rode uma vez)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "INSTALL_MASK_RCNN = True\n",
    "INSTALL_YOLO = True\n",
    "\n",
    "def pip_install(packages):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', *packages])\n",
    "\n",
    "base_packages = ['opencv-python-headless', 'pyyaml']\n",
    "\n",
    "if INSTALL_MASK_RCNN:\n",
    "    pip_install(['git+https://github.com/facebookresearch/detectron2.git', 'Pillow==10.3.0', *base_packages])\n",
    "\n",
    "if INSTALL_YOLO:\n",
    "    pip_install(['ultralytics>=8.3', *base_packages])\n",
    "\n",
    "MODEL_TYPE = 'mask_rcnn'  # ou 'yolo'\n",
    "CONF_THRESHOLD = 0.4\n",
    "INCLUDE_SEGMENTATION = False\n",
    "SAMPLE_INDEX = 0\n",
    "\n",
    "IMAGE_ROOT = os.path.join(extract_dir, 'images')\n",
    "MODEL_ROOT = os.path.join(extract_dir, 'models')\n",
    "\n",
    "if not os.path.isdir(IMAGE_ROOT):\n",
    "    IMAGE_ROOT = extract_dir\n",
    "\n",
    "if not os.path.isdir(MODEL_ROOT):\n",
    "    MODEL_ROOT = extract_dir\n",
    "\n",
    "image_paths = []\n",
    "for ext in ('*.png', '*.jpg', '*.jpeg'):\n",
    "    image_paths.extend(glob.glob(os.path.join(IMAGE_ROOT, '**', ext), recursive=True))\n",
    "image_paths = sorted(image_paths)\n",
    "\n",
    "print('Total imagens:', len(image_paths))\n",
    "print('Primeira imagem:', image_paths[0] if image_paths else '(nenhuma)')\n",
    "\n",
    "MASK_MODEL_PATH = os.path.join(MODEL_ROOT, 'model.pth')\n",
    "YOLO_MODEL_PATH = os.path.join(MODEL_ROOT, 'best.pt')\n",
    "\n",
    "if not os.path.exists(MASK_MODEL_PATH):\n",
    "    mask_candidates = glob.glob(os.path.join(MODEL_ROOT, '**', '*.pth'), recursive=True)\n",
    "    if mask_candidates:\n",
    "        MASK_MODEL_PATH = mask_candidates[0]\n",
    "\n",
    "if not os.path.exists(YOLO_MODEL_PATH):\n",
    "    yolo_candidates = glob.glob(os.path.join(MODEL_ROOT, '**', '*.pt'), recursive=True)\n",
    "    if yolo_candidates:\n",
    "        YOLO_MODEL_PATH = yolo_candidates[0]\n",
    "\n",
    "DATA_YAML_PATH = os.path.join(MODEL_ROOT, 'data.yaml')\n",
    "YOLO_CLASS_NAMES = None\n",
    "if os.path.exists(DATA_YAML_PATH):\n",
    "    import yaml\n",
    "    with open(DATA_YAML_PATH, 'r') as f:\n",
    "        payload = yaml.safe_load(f) or {}\n",
    "    YOLO_CLASS_NAMES = payload.get('names')\n",
    "\n",
    "print('Mask R-CNN:', MASK_MODEL_PATH, os.path.exists(MASK_MODEL_PATH))\n",
    "print('YOLO:', YOLO_MODEL_PATH, os.path.exists(YOLO_MODEL_PATH))\n",
    "print('YOLO classes (data.yaml):', YOLO_CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Gerar JSON (batch + unico)\n",
    "Substitua `run_model` pelo seu pipeline real.\n",
    "O retorno esperado: lista de dicts com `label`, `confidence` (opcional), `bbox`/`segmentation` (opcional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "MASK_CLASS_NAMES = ['dente', 'dentina', 'polpa', 'restauracao', 'carie']\n",
    "\n",
    "def load_model():\n",
    "    if MODEL_TYPE == 'mask_rcnn':\n",
    "        from detectron2.config import get_cfg\n",
    "        from detectron2 import model_zoo\n",
    "        from detectron2.engine import DefaultPredictor\n",
    "        import torch\n",
    "\n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml'))\n",
    "        cfg.MODEL.WEIGHTS = MASK_MODEL_PATH\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MASK_CLASS_NAMES)\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = CONF_THRESHOLD\n",
    "        cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 3.0]]\n",
    "        cfg.MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION = 28\n",
    "        cfg.MODEL.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        return {'type': 'mask_rcnn', 'predictor': predictor}\n",
    "\n",
    "    if MODEL_TYPE == 'yolo':\n",
    "        from ultralytics import YOLO\n",
    "        model = YOLO(YOLO_MODEL_PATH)\n",
    "        return {'type': 'yolo', 'model': model}\n",
    "\n",
    "    raise ValueError('MODEL_TYPE invalido.')\n",
    "\n",
    "def mask_to_polygon(mask):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    mask = (mask > 0).astype('uint8')\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    if contour is None or len(contour) < 3:\n",
    "        return None\n",
    "    points = contour.squeeze()\n",
    "    if points.ndim != 2:\n",
    "        return None\n",
    "    return points.astype(float).tolist()\n",
    "\n",
    "def get_label_from_names(names_source, class_id):\n",
    "    if isinstance(names_source, dict):\n",
    "        return names_source.get(class_id, names_source.get(str(class_id), str(class_id)))\n",
    "    if isinstance(names_source, list):\n",
    "        return names_source[class_id] if class_id < len(names_source) else str(class_id)\n",
    "    return str(class_id)\n",
    "\n",
    "def run_model(image_path, model):\n",
    "    if model['type'] == 'mask_rcnn':\n",
    "        import cv2\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return []\n",
    "        outputs = model['predictor'](img)\n",
    "        instances = outputs['instances'].to('cpu')\n",
    "        if len(instances) == 0:\n",
    "            return []\n",
    "        boxes = instances.pred_boxes.tensor.numpy()\n",
    "        scores = instances.scores.numpy()\n",
    "        classes = instances.pred_classes.numpy()\n",
    "        masks = instances.pred_masks.numpy() if INCLUDE_SEGMENTATION else None\n",
    "\n",
    "        findings = []\n",
    "        for i in range(len(classes)):\n",
    "            score = float(scores[i])\n",
    "            if score < CONF_THRESHOLD:\n",
    "                continue\n",
    "            class_id = int(classes[i])\n",
    "            label = MASK_CLASS_NAMES[class_id] if class_id < len(MASK_CLASS_NAMES) else str(class_id)\n",
    "            item = {\n",
    "                'label': label,\n",
    "                'confidence': score,\n",
    "                'bbox': boxes[i].tolist(),\n",
    "            }\n",
    "            if INCLUDE_SEGMENTATION and masks is not None:\n",
    "                polygon = mask_to_polygon(masks[i])\n",
    "                if polygon:\n",
    "                    item['segmentation'] = polygon\n",
    "            findings.append(item)\n",
    "        return findings\n",
    "\n",
    "    if model['type'] == 'yolo':\n",
    "        results = model['model'](image_path, verbose=False)\n",
    "        if not results:\n",
    "            return []\n",
    "        result = results[0]\n",
    "        boxes = result.boxes\n",
    "        masks = result.masks\n",
    "        names = result.names or YOLO_CLASS_NAMES\n",
    "\n",
    "        findings = []\n",
    "        if boxes is None:\n",
    "            return findings\n",
    "        for i in range(len(boxes)):\n",
    "            score = float(boxes.conf[i])\n",
    "            if score < CONF_THRESHOLD:\n",
    "                continue\n",
    "            class_id = int(boxes.cls[i])\n",
    "            label = get_label_from_names(names, class_id)\n",
    "            item = {\n",
    "                'label': label,\n",
    "                'confidence': score,\n",
    "                'bbox': boxes.xyxy[i].tolist(),\n",
    "            }\n",
    "            if INCLUDE_SEGMENTATION and masks is not None and masks.xy is not None and i < len(masks.xy):\n",
    "                poly = masks.xy[i]\n",
    "                if poly is not None and len(poly) >= 3:\n",
    "                    item['segmentation'] = [[float(x), float(y)] for x, y in poly]\n",
    "            findings.append(item)\n",
    "        return findings\n",
    "\n",
    "    raise ValueError('Modelo nao suportado.')\n",
    "\n",
    "if not image_paths:\n",
    "    raise SystemExit('Nenhuma imagem encontrada.')\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "cases = []\n",
    "total = len(image_paths)\n",
    "for idx, path in enumerate(image_paths, start=1):\n",
    "    name = os.path.basename(path)\n",
    "    if idx % 5 == 0 or idx == 1:\n",
    "        print(f'Processando {idx}/{total}: {name}')\n",
    "    findings = run_model(path, model)\n",
    "    cases.append({\n",
    "        'name': name,\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'findings': findings,\n",
    "    })\n",
    "\n",
    "batch_path = '/content/triagem_batch_results.json'\n",
    "with open(batch_path, 'w') as f:\n",
    "    json.dump(cases, f, ensure_ascii=True, indent=2)\n",
    "\n",
    "sample_index = min(max(SAMPLE_INDEX, 0), len(cases) - 1)\n",
    "single_case = cases[sample_index]\n",
    "single_path = '/content/triagem_single_result.json'\n",
    "with open(single_path, 'w') as f:\n",
    "    json.dump(single_case, f, ensure_ascii=True, indent=2)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(batch_path)\n",
    "files.download(single_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, importe o JSON na pagina de triagem usando o botao \"Importar JSON\".\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "triagem_batch_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}